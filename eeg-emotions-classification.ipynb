{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/eeg-brainwave-dataset-feeling-emotions/emotions.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/eeg-brainwave-dataset-feeling-emotions/emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.62</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.60</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.70</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.150</td>\n",
       "      <td>...</td>\n",
       "      <td>23.50</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.50</td>\n",
       "      <td>-215.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.80</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.80</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-4.820</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.30</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-21.8</td>\n",
       "      <td>-23.30</td>\n",
       "      <td>182.00</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.90</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.70</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.20</td>\n",
       "      <td>89.90</td>\n",
       "      <td>2.030</td>\n",
       "      <td>...</td>\n",
       "      <td>462.00</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>462.00</td>\n",
       "      <td>-267.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.90</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1.970</td>\n",
       "      <td>...</td>\n",
       "      <td>299.00</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>299.00</td>\n",
       "      <td>132.00</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.30</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.06</td>\n",
       "      <td>41.40</td>\n",
       "      <td>5.520</td>\n",
       "      <td>...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>38.1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>12.00</td>\n",
       "      <td>119.00</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.00</td>\n",
       "      <td>30.9</td>\n",
       "      <td>29.6</td>\n",
       "      <td>28.50</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.650</td>\n",
       "      <td>1.540</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.87</td>\n",
       "      <td>-1.210</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>30.2</td>\n",
       "      <td>30.2</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>134.00</td>\n",
       "      <td>3.59</td>\n",
       "      <td>-12.70</td>\n",
       "      <td>-12.70</td>\n",
       "      <td>3.59</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.80</td>\n",
       "      <td>21.0</td>\n",
       "      <td>44.7</td>\n",
       "      <td>4.87</td>\n",
       "      <td>28.1</td>\n",
       "      <td>2.140</td>\n",
       "      <td>1.020</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-4.390</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.60</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>-15.60</td>\n",
       "      <td>89.50</td>\n",
       "      <td>40.60</td>\n",
       "      <td>-55.20</td>\n",
       "      <td>-55.20</td>\n",
       "      <td>40.60</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.80</td>\n",
       "      <td>27.8</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>26.9</td>\n",
       "      <td>-3.210</td>\n",
       "      <td>-1.950</td>\n",
       "      <td>9.80</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>-0.955</td>\n",
       "      <td>...</td>\n",
       "      <td>-177.00</td>\n",
       "      <td>32.8</td>\n",
       "      <td>32.8</td>\n",
       "      <td>-177.00</td>\n",
       "      <td>-417.00</td>\n",
       "      <td>384.00</td>\n",
       "      <td>-186.00</td>\n",
       "      <td>-186.00</td>\n",
       "      <td>384.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.50</td>\n",
       "      <td>29.7</td>\n",
       "      <td>34.9</td>\n",
       "      <td>10.20</td>\n",
       "      <td>26.9</td>\n",
       "      <td>-38.000</td>\n",
       "      <td>-1.650</td>\n",
       "      <td>3.89</td>\n",
       "      <td>-33.50</td>\n",
       "      <td>-3.300</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.38</td>\n",
       "      <td>38.7</td>\n",
       "      <td>38.7</td>\n",
       "      <td>-8.38</td>\n",
       "      <td>115.00</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.91</td>\n",
       "      <td>29.2</td>\n",
       "      <td>-314.0</td>\n",
       "      <td>6.51</td>\n",
       "      <td>30.9</td>\n",
       "      <td>-1.880</td>\n",
       "      <td>1.900</td>\n",
       "      <td>11.90</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>5.700</td>\n",
       "      <td>...</td>\n",
       "      <td>226.00</td>\n",
       "      <td>-81.8</td>\n",
       "      <td>-81.8</td>\n",
       "      <td>226.00</td>\n",
       "      <td>1.84</td>\n",
       "      <td>99.40</td>\n",
       "      <td>-40.30</td>\n",
       "      <td>-40.30</td>\n",
       "      <td>99.40</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
       "0        4.62      30.3    -356.0     15.60      26.3       1.070       0.411   \n",
       "1       28.80      33.1      32.0     25.80      22.8       6.550       1.680   \n",
       "2        8.90      29.4    -416.0     16.70      23.7      79.900       3.360   \n",
       "3       14.90      31.6    -143.0     19.80      24.3      -0.584      -0.284   \n",
       "4       28.30      31.3      45.2     27.30      24.5      34.800      -5.790   \n",
       "5       31.00      30.9      29.6     28.50      24.0       1.650       1.540   \n",
       "6       10.80      21.0      44.7      4.87      28.1       2.140       1.020   \n",
       "7       17.80      27.8    -102.0     16.90      26.9      -3.210      -1.950   \n",
       "8       11.50      29.7      34.9     10.20      26.9     -38.000      -1.650   \n",
       "9        8.91      29.2    -314.0      6.51      30.9      -1.880       1.900   \n",
       "\n",
       "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
       "0      -15.70        2.06       3.150  ...      23.50       20.3       20.3   \n",
       "1        2.88        3.83      -4.820  ...     -23.30      -21.8      -21.8   \n",
       "2       90.20       89.90       2.030  ...     462.00     -233.0     -233.0   \n",
       "3        8.82        2.30      -1.970  ...     299.00     -243.0     -243.0   \n",
       "4        3.06       41.40       5.520  ...      12.00       38.1       38.1   \n",
       "5        3.83        1.87      -1.210  ...      -1.48       30.2       30.2   \n",
       "6       13.20        1.16      -4.390  ...     -15.60      -41.0      -41.0   \n",
       "7        9.80       -3.24      -0.955  ...    -177.00       32.8       32.8   \n",
       "8        3.89      -33.50      -3.300  ...      -8.38       38.7       38.7   \n",
       "9       11.90       -3.60       5.700  ...     226.00      -81.8      -81.8   \n",
       "\n",
       "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b     label  \n",
       "0      23.50    -215.00     280.00    -162.00    -162.00     280.00  NEGATIVE  \n",
       "1     -23.30     182.00       2.57     -31.60     -31.60       2.57   NEUTRAL  \n",
       "2     462.00    -267.00     281.00    -148.00    -148.00     281.00  POSITIVE  \n",
       "3     299.00     132.00     -12.40       9.53       9.53     -12.40  POSITIVE  \n",
       "4      12.00     119.00     -17.60      23.90      23.90     -17.60   NEUTRAL  \n",
       "5      -1.48     134.00       3.59     -12.70     -12.70       3.59   NEUTRAL  \n",
       "6     -15.60      89.50      40.60     -55.20     -55.20      40.60  POSITIVE  \n",
       "7    -177.00    -417.00     384.00    -186.00    -186.00     384.00  NEGATIVE  \n",
       "8      -8.38     115.00      -7.00       3.20       3.20      -7.00   NEUTRAL  \n",
       "9     226.00       1.84      99.40     -40.30     -40.30      99.40  NEGATIVE  \n",
       "\n",
       "[10 rows x 2549 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2132, 2549)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values in this dataset, it will make things easier going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2132 entries, 0 to 2131\n",
      "Columns: 2549 entries, # mean_0_a to label\n",
      "dtypes: float64(2548), object(1)\n",
      "memory usage: 41.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69608594,  0.35491199, -1.21724379, ..., -1.06084278,\n",
       "        -1.06084278,  0.91015287],\n",
       "       [ 0.88626748,  0.65719091,  0.66420935, ...,  0.16401498,\n",
       "         0.16401498, -0.45550631],\n",
       "       [-0.41600022,  0.25775091, -1.50819016, ..., -0.92933964,\n",
       "        -0.92933964,  0.91507541],\n",
       "       ...,\n",
       "       [-1.03421746,  0.13899848, -0.74688051, ...,  0.36220899,\n",
       "         0.36220899, -1.30006583],\n",
       "       [ 0.10098042, -0.76783828, -0.88750458, ..., -2.0846886 ,\n",
       "        -2.0846886 ,  2.24908269],\n",
       "       [ 0.76847442,  0.53843848,  0.66323953, ...,  0.67499859,\n",
       "         0.67499859, -0.50118745]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1428, 2548)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "parameters_svc = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "grid_search_svc = GridSearchCV(SVC(), parameters_svc, n_jobs=-1)\n",
    "grid_search_svc.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9663992148202676"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_job...\n",
       "                                           verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'base_score': [0.5],\n",
       "                                        'colsample_bylevel': [1],\n",
       "                                        'colsample_bytree': [0.6, 0.8, 1],\n",
       "                                        'gamma': [0, 0.1, 0.2],\n",
       "                                        'learning_rate': [0.1, 0.2, 0.3],\n",
       "                                        'max_delta_step': [0],\n",
       "                                        'max_depth': [3, 4, 5],\n",
       "                                        'min_child_weight': [0, 0.5, 1],\n",
       "                                        'n_estimators': [50, 100, 150],\n",
       "                                        'reg_alpha': [0, 0.01, 1, 10.0],\n",
       "                                        'reg_lambda': [0, 0.01, 1, 10.0],\n",
       "                                        'subsample': [0.7, 0.8, 0.9, 1]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "parameters_xgb =    {\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'learning_rate': [0.1, 0.2, 0.3],\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'gamma': [0, 0.1, 0.2],\n",
    "            'min_child_weight': [0, 0.5, 1],\n",
    "            'max_delta_step': [0],\n",
    "            'subsample': [0.7, 0.8, 0.9, 1],\n",
    "            'colsample_bytree': [0.6, 0.8, 1],\n",
    "            'colsample_bylevel': [1],\n",
    "            'reg_alpha': [0, 1e-2, 1, 1e1],\n",
    "            'reg_lambda': [0, 1e-2, 1, 1e1],\n",
    "            'base_score': [0.5]\n",
    "            }\n",
    "\n",
    "search_xgb = RandomizedSearchCV(xgb_clf, parameters_xgb, n_jobs=-1)\n",
    "search_xgb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888062814378603"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_xgb.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING AN ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 1, 32)             81568     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1, 32)             1056      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1, 32)             1056      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 3)              99        \n",
      "=================================================================\n",
      "Total params: 83,779\n",
      "Trainable params: 83,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(1,2548)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train_ann, X_val_ann, y_train_ann, y_val_ann = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "y_train_ann = to_categorical(y_train_ann, 3)\n",
    "y_val_ann = to_categorical(y_val_ann, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5111e-05 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4714e-05 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4315e-05 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.3874e-05 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.3514e-05 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.3128e-05 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2791e-05 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2418e-05 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2121e-05 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1818e-05 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1471e-05 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1181e-05 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.0866e-05 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.0594e-05 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.0318e-05 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.0067e-05 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.8054e-06 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.5426e-06 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 9.3252e-06 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 9.5867e-06 - accuracy: 1.00 - 0s 2ms/step - loss: 9.0638e-06 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.8252e-06 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.6123e-06 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.4238e-06 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 8.2308e-06 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.9934e-06 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.7964e-06 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.6095e-06 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.4319e-06 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.2658e-06 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 7.0606e-06 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.9142e-06 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.7284e-06 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.5838e-06 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.4293e-06 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.2892e-06 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 6.1339e-06 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.9798e-06 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.8429e-06 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.7096e-06 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5785e-06 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.4437e-06 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.2897e-06 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.1630e-06 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 5.0508e-06 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 4.9249e-06 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 4.8179e-06 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 4.6994e-06 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 4.5893e-06 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 4.4709e-06 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 4.3568e-06 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 4.2690e-06 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 4.1563e-06 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 4.0529e-06 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.9555e-06 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.8492e-06 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.7544e-06 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.6641e-06 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.5769e-06 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.4918e-06 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.4085e-06 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.3170e-06 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.2362e-06 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.1545e-06 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.0808e-06 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.9948e-06 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.9171e-06 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.8455e-06 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.7766e-06 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.7120e-06 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.6435e-06 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.5892e-06 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.5180e-06 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.4590e-06 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.4051e-06 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.3474e-06 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.2920e-06 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.2409e-06 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.1893e-06 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.1435e-06 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.0883e-06 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.0408e-06 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9995e-06 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9552e-06 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.9066e-06 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.8622e-06 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.8224e-06 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.7868e-06 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.7469e-06 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.7047e-06 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.6653e-06 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.6304e-06 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5962e-06 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5601e-06 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5232e-06 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4924e-06 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4592e-06 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4296e-06 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.3965e-06 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.3673e-06 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.3399e-06 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_ann, y_train_ann, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16032983362674713, 0.9745762944221497]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val_ann, y_val_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb = search_xgb.best_estimator_\n",
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857954545454546"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
